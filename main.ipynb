{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/daniyarzakarin/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/06/2023 22:15:17 - INFO - pytorch_pretrained_bert.modeling -   loading archive file models/sentiment/finbert\n",
      "05/06/2023 22:15:17 - INFO - pytorch_pretrained_bert.modeling -   Model config {\n",
      "  \"_name_or_path\": \"/home/ubuntu/finbert/models/language_model/finbertTRC2\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"positive\",\n",
      "    \"1\": \"negative\",\n",
      "    \"2\": \"neutral\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"negative\": 1,\n",
      "    \"neutral\": 2,\n",
      "    \"positive\": 0\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "05/06/2023 22:15:20 - INFO - pytorch_pretrained_bert.modeling -   Weights from pretrained model not used in BertForSequenceClassification: ['bert.embeddings.position_ids']\n"
     ]
    }
   ],
   "source": [
    "from pytorch_pretrained_bert.modeling import BertForSequenceClassification\n",
    "from finbert.finbert import predict\n",
    "model = BertForSequenceClassification.from_pretrained('models/sentiment/finbert', num_labels=3, cache_dir=None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/06/2023 22:15:20 - INFO - root -   Using device: cpu \n",
      "05/06/2023 22:15:20 - INFO - finbert.utils -   *** Example ***\n",
      "05/06/2023 22:15:20 - INFO - finbert.utils -   guid: 0\n",
      "05/06/2023 22:15:20 - INFO - finbert.utils -   tokens: [CLS] the shares jumped to 76 euros on opening and were trading at 75 euros at 07 ##19 gm ##t . [SEP]\n",
      "05/06/2023 22:15:20 - INFO - finbert.utils -   input_ids: 101 1996 6661 5598 2000 6146 19329 2006 3098 1998 2020 6202 2012 4293 19329 2012 5718 16147 13938 2102 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/06/2023 22:15:20 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/06/2023 22:15:20 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/06/2023 22:15:20 - INFO - finbert.utils -   label: None (id = 9090)\n",
      "05/06/2023 22:15:20 - INFO - root -   tensor([ 1.7448, -1.5406, -1.4323])\n"
     ]
    },
    {
     "ename": "AxisError",
     "evalue": "axis 1 is out of bounds for array of dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAxisError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m text \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mThe shares jumped to 76 euros on opening and were trading at 75 euros at 0719 GMT.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m predict(text, model)\u001b[39m.\u001b[39mto_json(orient\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mrecords\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/code/finBERT/finbert/finbert.py:624\u001b[0m, in \u001b[0;36mpredict\u001b[0;34m(text, model, write_to_csv, path, use_gpu, gpu_name, batch_size)\u001b[0m\n\u001b[1;32m    622\u001b[0m logits \u001b[39m=\u001b[39m model(all_input_ids, all_attention_mask, all_token_type_ids)[\u001b[39m0\u001b[39m]\n\u001b[1;32m    623\u001b[0m logging\u001b[39m.\u001b[39minfo(logits)\n\u001b[0;32m--> 624\u001b[0m logits \u001b[39m=\u001b[39m softmax(np\u001b[39m.\u001b[39;49marray(logits\u001b[39m.\u001b[39;49mcpu()))\n\u001b[1;32m    625\u001b[0m sentiment_score \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mSeries(logits[:, \u001b[39m0\u001b[39m] \u001b[39m-\u001b[39m logits[:, \u001b[39m1\u001b[39m])\n\u001b[1;32m    626\u001b[0m predictions \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msqueeze(np\u001b[39m.\u001b[39margmax(logits, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m))\n",
      "File \u001b[0;32m~/Documents/code/finBERT/finbert/utils.py:214\u001b[0m, in \u001b[0;36msoftmax\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msoftmax\u001b[39m(x):\n\u001b[1;32m    213\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Compute softmax values for each sets of scores in x.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 214\u001b[0m     e_x \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mexp(x \u001b[39m-\u001b[39m np\u001b[39m.\u001b[39;49mmax(x, axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)[:, \u001b[39mNone\u001b[39;00m])\n\u001b[1;32m    215\u001b[0m     \u001b[39mreturn\u001b[39;00m e_x \u001b[39m/\u001b[39m np\u001b[39m.\u001b[39msum(e_x, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)[:, \u001b[39mNone\u001b[39;00m]\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mamax\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/Documents/code/finBERT/.venv/lib/python3.9/site-packages/numpy/core/fromnumeric.py:2820\u001b[0m, in \u001b[0;36mamax\u001b[0;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2703\u001b[0m \u001b[39m@array_function_dispatch\u001b[39m(_amax_dispatcher)\n\u001b[1;32m   2704\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mamax\u001b[39m(a, axis\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, out\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, keepdims\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39m_NoValue, initial\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39m_NoValue,\n\u001b[1;32m   2705\u001b[0m          where\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39m_NoValue):\n\u001b[1;32m   2706\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   2707\u001b[0m \u001b[39m    Return the maximum of an array or maximum along an axis.\u001b[39;00m\n\u001b[1;32m   2708\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2818\u001b[0m \u001b[39m    5\u001b[39;00m\n\u001b[1;32m   2819\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2820\u001b[0m     \u001b[39mreturn\u001b[39;00m _wrapreduction(a, np\u001b[39m.\u001b[39;49mmaximum, \u001b[39m'\u001b[39;49m\u001b[39mmax\u001b[39;49m\u001b[39m'\u001b[39;49m, axis, \u001b[39mNone\u001b[39;49;00m, out,\n\u001b[1;32m   2821\u001b[0m                           keepdims\u001b[39m=\u001b[39;49mkeepdims, initial\u001b[39m=\u001b[39;49minitial, where\u001b[39m=\u001b[39;49mwhere)\n",
      "File \u001b[0;32m~/Documents/code/finBERT/.venv/lib/python3.9/site-packages/numpy/core/fromnumeric.py:86\u001b[0m, in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     84\u001b[0m             \u001b[39mreturn\u001b[39;00m reduction(axis\u001b[39m=\u001b[39maxis, out\u001b[39m=\u001b[39mout, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpasskwargs)\n\u001b[0;32m---> 86\u001b[0m \u001b[39mreturn\u001b[39;00m ufunc\u001b[39m.\u001b[39;49mreduce(obj, axis, dtype, out, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mpasskwargs)\n",
      "\u001b[0;31mAxisError\u001b[0m: axis 1 is out of bounds for array of dimension 1"
     ]
    }
   ],
   "source": [
    "text = \"The shares jumped to 76 euros on opening and were trading at 75 euros at 0719 GMT.\"\n",
    "predict(text, model).to_json(orient='records')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
